#!/usr/bin/env python3
"""
ä½¿ç”¨Polarsä¼˜åŒ–çš„Excelæ–‡ä»¶åˆå¹¶å·¥å…· - æ™ºèƒ½æ—¥æœŸæ’åºç‰ˆæœ¬
é‡‡ç”¨æ··åˆæ–¹æ¡ˆï¼špandasè¯»å–Excel + Polarsé«˜æ€§èƒ½åˆå¹¶ + pandasè¾“å‡ºExcel
åŠŸèƒ½ï¼š
1. æ™ºèƒ½æ–‡ä»¶è¯»å–ç­–ç•¥ï¼ˆæ ¹æ®æ–‡ä»¶å¤§å°é€‰æ‹©æœ€ä¼˜è¯»å–æ–¹å¼ï¼‰
2. pandasåˆ°Polarsçš„é«˜æ•ˆè½¬æ¢
3. æ‰¹é‡å¤„ç†æ”¯æŒï¼ˆé¿å…å†…å­˜æº¢å‡ºï¼‰
4. å†…å­˜ä¼˜åŒ–å’Œæ€§èƒ½ç›‘æ§
5. å®Œå–„çš„é”™è¯¯å¤„ç†å’Œè¿›åº¦æ˜¾ç¤º
6. ğŸ”¥ æ™ºèƒ½æ—¥æœŸæ’åºï¼šæ”¯æŒYYYY_MMDD_*å’ŒMMDD_*ä¸¤ç§æ–‡ä»¶åæ ¼å¼
éµå¾ªUnixè®¾è®¡å“²å­¦ï¼šä¸“æ³¨åšå¥½ä¸€ä»¶äº‹
"""

import argparse
import gc
import os
import re
import sys
import time
from datetime import datetime
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Tuple, Optional
import warnings

import pandas as pd
import polars as pl
import psutil
from tqdm import tqdm

# å¿½ç•¥ç‰¹å®šè­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning)

# é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
PATTERN_WITH_YEAR = re.compile(r'^(\d{4})_(\d{2})(\d{2})_')
PATTERN_WITHOUT_YEAR = re.compile(r'^(\d{2})(\d{2})_')


class MemoryMonitor:
    """å†…å­˜ä½¿ç”¨ç›‘æ§å™¨"""
    
    def __init__(self, limit_percent=80):
        self.limit_percent = limit_percent
        self.process = psutil.Process()
        self.initial_memory = self.get_memory_usage()
    
    def get_memory_usage(self):
        """è·å–å½“å‰å†…å­˜ä½¿ç”¨é‡ï¼ˆMBï¼‰"""
        return self.process.memory_info().rss / 1024 / 1024
    
    def get_memory_percent(self):
        """è·å–å†…å­˜ä½¿ç”¨ç™¾åˆ†æ¯”"""
        return psutil.virtual_memory().percent
    
    def check_memory(self):
        """æ£€æŸ¥å†…å­˜ä½¿ç”¨æ˜¯å¦è¶…é™"""
        return self.get_memory_percent() < self.limit_percent
    
    def get_memory_info(self):
        """è·å–å†…å­˜ä½¿ç”¨ä¿¡æ¯"""
        current = self.get_memory_usage()
        percent = self.get_memory_percent()
        return {
            'current_mb': current,
            'used_mb': current - self.initial_memory,
            'percent': percent
        }


def get_file_size_mb(file_path: Path) -> float:
    """è·å–æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰"""
    return file_path.stat().st_size / 1024 / 1024


def extract_date_from_filename(file_path: Path) -> Tuple[int, int, int, str]:
    """
    æ™ºèƒ½æå–æ–‡ä»¶åä¸­çš„æ—¥æœŸä¿¡æ¯
    
    æ”¯æŒæ ¼å¼:
    - 2023_0101_data.xlsx â†’ (2023, 1, 1)
    - 0328_data.xlsx â†’ (2024, 3, 28) # é»˜è®¤å¹´ä»½
    
    Returns:
        tuple: (å¹´, æœˆ, æ—¥, æ–‡ä»¶å) ç”¨äºæ’åº
    """
    filename = file_path.stem
    
    # æ ¼å¼1: YYYY_MMDD_* (ä¼˜å…ˆåŒ¹é…)
    match = PATTERN_WITH_YEAR.match(filename)
    if match:
        year, month, day = map(int, match.groups())
        # å¿«é€Ÿæœ‰æ•ˆæ€§æ£€æŸ¥
        if 1 <= month <= 12 and 1 <= day <= 31 and 1900 <= year <= 2100:
            try:
                # ä¸¥æ ¼æ—¥æœŸéªŒè¯ï¼ˆå¤„ç†å¦‚0230è¿™ç§æ— æ•ˆæ—¥æœŸï¼‰
                datetime(year, month, day)
                return (year, month, day, file_path.name)
            except ValueError:
                pass
    
    # æ ¼å¼2: MMDD_*
    match = PATTERN_WITHOUT_YEAR.match(filename)
    if match:
        month, day = map(int, match.groups())
        if 1 <= month <= 12 and 1 <= day <= 31:
            try:
                # ä½¿ç”¨é»˜è®¤å¹´ä»½2024
                datetime(2024, month, day)
                return (2024, month, day, file_path.name)
            except ValueError:
                pass
    
    # è§£æå¤±è´¥ï¼šä½¿ç”¨æœ€å°å€¼ç¡®ä¿æ’åœ¨æœ€å‰é¢ï¼Œä¾¿äºè°ƒè¯•
    return (0, 0, 0, file_path.name)


def find_valid_xlsx_files(directory: str) -> List[Path]:
    """
    æŸ¥æ‰¾ç›®å½•ä¸­æœ‰æ•ˆçš„xlsxæ–‡ä»¶å¹¶æŒ‰æ—¥æœŸæ’åº
    
    æ™ºèƒ½æ’åºæ”¯æŒ:
    - 2023_0101_* < 2023_0328_* < 2023_1102_* 
    - 2023_1102_* < 2024_0101_*
    - 0101_* < 0328_* < 1102_* (é»˜è®¤2024å¹´)
    
    Args:
        directory: ç›®å½•è·¯å¾„
    
    Returns:
        list: æŒ‰æ—¥æœŸæ’åºçš„æœ‰æ•ˆxlsxæ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    directory = Path(directory)
    if not directory.exists():
        return []
    
    # è·å–æ‰€æœ‰xlsxæ–‡ä»¶ï¼Œæ’é™¤ä¸´æ—¶æ–‡ä»¶å’Œç³»ç»Ÿæ–‡ä»¶
    xlsx_files = []
    for file_path in directory.glob("*.xlsx"):
        if not file_path.name.startswith(('~$', '.', '#')):
            xlsx_files.append(file_path)
    
    if not xlsx_files:
        return []
    
    print(f"ğŸ” æ™ºèƒ½æ—¥æœŸæ’åºï¼šåˆ†æ {len(xlsx_files)} ä¸ªæ–‡ä»¶...")
    
    # æå–æ‰€æœ‰æ–‡ä»¶çš„æ—¥æœŸä¿¡æ¯
    files_with_dates = []
    parse_stats = {'with_year': 0, 'without_year': 0, 'failed': 0}
    year_range = set()
    
    for file_path in xlsx_files:
        year, month, day, filename = extract_date_from_filename(file_path)
        files_with_dates.append((year, month, day, file_path))
        
        # ç»Ÿè®¡è§£æç»“æœ
        if year == 0:
            parse_stats['failed'] += 1
        elif year == 2024 and PATTERN_WITHOUT_YEAR.match(file_path.stem):
            parse_stats['without_year'] += 1
        else:
            parse_stats['with_year'] += 1
            year_range.add(year)
    
    # æ˜¾ç¤ºè§£æç»Ÿè®¡
    print(f"ğŸ“Š è§£æç»Ÿè®¡:")
    print(f"  âœ“ æœ‰å¹´ä»½æ ¼å¼ (YYYY_MMDD_*): {parse_stats['with_year']} ä¸ª")
    if year_range:
        print(f"    å¹´ä»½èŒƒå›´: {min(year_range)}-{max(year_range)}")
    print(f"  âœ“ æ— å¹´ä»½æ ¼å¼ (MMDD_*): {parse_stats['without_year']} ä¸ª (é»˜è®¤2024å¹´)")
    if parse_stats['failed'] > 0:
        print(f"  âš  è§£æå¤±è´¥: {parse_stats['failed']} ä¸ª (å°†æ”¾åœ¨æœ€å‰é¢)")
    
    # æŒ‰æ—¥æœŸæ’åºï¼š(å¹´, æœˆ, æ—¥) å…ƒç»„è‡ªç„¶æ’åº
    sorted_files_with_dates = sorted(files_with_dates, key=lambda x: (x[0], x[1], x[2]))
    
    # æå–æ’åºåçš„æ–‡ä»¶è·¯å¾„
    sorted_files = [item[3] for item in sorted_files_with_dates]
    
    # æ˜¾ç¤ºæ’åºç»“æœç¤ºä¾‹
    if len(sorted_files) <= 10:
        print(f"ğŸ“… æ’åºç»“æœ: {[f.name for f in sorted_files]}")
    else:
        first_3 = [f.name for f in sorted_files[:3]]
        last_3 = [f.name for f in sorted_files[-3:]]
        print(f"ğŸ“… æ’åºç»“æœç¤ºä¾‹: {first_3} ... {last_3}")
    
    return sorted_files


def validate_column_consistency(file_paths: List[Path]) -> Tuple[bool, Optional[List[str]], Optional[str]]:
    """
    éªŒè¯æ‰€æœ‰æ–‡ä»¶çš„åˆ—ç»“æ„ä¸€è‡´æ€§
    
    Args:
        file_paths: xlsxæ–‡ä»¶è·¯å¾„åˆ—è¡¨
    
    Returns:
        tuple: (æ˜¯å¦ä¸€è‡´, ç»Ÿä¸€åˆ—å, é”™è¯¯ä¿¡æ¯)
    """
    if not file_paths:
        return False, None, "æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆæ–‡ä»¶"
    
    reference_columns = None
    
    for file_path in file_paths:
        try:
            # åªè¯»å–ç¬¬ä¸€è¡Œè·å–åˆ—åï¼Œæé«˜æ€§èƒ½
            df_sample = pd.read_excel(file_path, nrows=0)
            current_columns = list(df_sample.columns)
            
            if reference_columns is None:
                reference_columns = current_columns
            elif current_columns != reference_columns:
                return False, None, f"æ–‡ä»¶ {file_path.name} çš„åˆ—ç»“æ„ä¸å…¶ä»–æ–‡ä»¶ä¸ä¸€è‡´"
                
        except Exception as e:
            return False, None, f"è¯»å–æ–‡ä»¶ {file_path.name} æ—¶å‡ºé”™: {e}"
    
    return True, reference_columns, None


def read_excel_optimized(file_path: Path, file_size_mb: float) -> Tuple[str, Optional[pl.DataFrame], Optional[str]]:
    """
    ä¼˜åŒ–çš„Excelè¯»å–ï¼Œç«‹å³è½¬æ¢ä¸ºPolars DataFrame
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        file_size_mb: æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰
    
    Returns:
        tuple: (æ–‡ä»¶å, Polars DataFrame, é”™è¯¯ä¿¡æ¯)
    """
    try:
        # æ ¹æ®æ–‡ä»¶å¤§å°é€‰æ‹©è¯»å–ç­–ç•¥
        if file_size_mb < 10:
            # å°æ–‡ä»¶ï¼šç›´æ¥pandasè¯»å–
            df_pandas = pd.read_excel(file_path, engine='openpyxl')
        else:
            # å¤§æ–‡ä»¶ï¼šä½¿ç”¨read_onlyæ¨¡å¼
            df_pandas = pd.read_excel(file_path, engine='openpyxl')
        
        # ç«‹å³è½¬æ¢ä¸ºPolars DataFrame
        df_polars = pl.from_pandas(df_pandas)
        
        # é‡Šæ”¾pandas DataFrameå†…å­˜
        del df_pandas
        gc.collect()
        
        return file_path.name, df_polars, None
        
    except Exception as e:
        return file_path.name, None, str(e)


def batch_process_files(
    file_paths: List[Path], 
    batch_size: int = 50,
    max_workers: int = None,
    progress_bar: Optional[tqdm] = None
) -> Tuple[List[pl.DataFrame], int]:
    """
    æ‰¹é‡å¤„ç†æ–‡ä»¶ï¼Œé¿å…å†…å­˜æº¢å‡º
    
    Args:
        file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        batch_size: æ¯æ‰¹å¤„ç†çš„æ–‡ä»¶æ•°
        max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
        progress_bar: è¿›åº¦æ¡å¯¹è±¡
    
    Returns:
        tuple: (Polars DataFrameåˆ—è¡¨, æ€»è¡Œæ•°)
    """
    if max_workers is None:
        max_workers = min(int(os.cpu_count() * 0.8), 4)
    
    all_dataframes = []
    total_rows = 0
    
    # åˆ†æ‰¹å¤„ç†
    for i in range(0, len(file_paths), batch_size):
        batch_files = file_paths[i:i + batch_size]
        batch_dfs = []
        
        # è·å–æ–‡ä»¶å¤§å°ä¿¡æ¯
        file_sizes = [(fp, get_file_size_mb(fp)) for fp in batch_files]
        
        # å¹¶è¡Œè¯»å–å½“å‰æ‰¹æ¬¡
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_file = {
                executor.submit(read_excel_optimized, fp, size): fp 
                for fp, size in file_sizes
            }
            
            for future in as_completed(future_to_file):
                filename, df, error = future.result()
                
                if error:
                    print(f"\nâœ— {filename}: è¯»å–å¤±è´¥ - {error}")
                    raise Exception(f"æ–‡ä»¶è¯»å–å¤±è´¥: {filename}")
                else:
                    batch_dfs.append(df)
                    rows = df.shape[0]
                    total_rows += rows
                    if progress_bar:
                        progress_bar.update(1)
                        progress_bar.set_postfix({'rows': total_rows})
        
        # åˆå¹¶å½“å‰æ‰¹æ¬¡
        if batch_dfs:
            # ä½¿ç”¨Polarsçš„é«˜æ•ˆconcat
            batch_merged = pl.concat(batch_dfs, rechunk=True)
            all_dataframes.append(batch_merged)
            
            # é‡Šæ”¾æ‰¹æ¬¡å†…çš„DataFrame
            del batch_dfs
            gc.collect()
    
    return all_dataframes, total_rows


def merge_with_polars(
    input_dir: str,
    output_file: Optional[str] = None,
    batch_size: int = 50,
    max_workers: Optional[int] = None,
    memory_limit: int = 80
) -> bool:
    """
    ä½¿ç”¨Polarsä¼˜åŒ–çš„æ–‡ä»¶åˆå¹¶ä¸»å‡½æ•°
    
    Args:
        input_dir: è¾“å…¥ç›®å½•è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        batch_size: æ‰¹å¤„ç†å¤§å°
        max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
        memory_limit: å†…å­˜ä½¿ç”¨é™åˆ¶ç™¾åˆ†æ¯”
    
    Returns:
        bool: æ˜¯å¦æˆåŠŸ
    """
    
    print(f"=== Polarsä¼˜åŒ–Excelæ–‡ä»¶åˆå¹¶å·¥å…· (æ™ºèƒ½æ—¥æœŸæ’åºç‰ˆ) ===")
    
    # åˆå§‹åŒ–å†…å­˜ç›‘æ§
    memory_monitor = MemoryMonitor(memory_limit)
    
    # 1. æŸ¥æ‰¾æœ‰æ•ˆæ–‡ä»¶å¹¶æŒ‰æ—¥æœŸæ’åº
    xlsx_files = find_valid_xlsx_files(input_dir)
    
    if not xlsx_files:
        print(f"åœ¨ç›®å½• {input_dir} ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„xlsxæ–‡ä»¶")
        return False
    
    print(f"\næ‰¾åˆ°å¹¶æ’åº {len(xlsx_files)} ä¸ªxlsxæ–‡ä»¶")
    print(f"å†…å­˜é™åˆ¶: {memory_limit}%")
    print(f"æ‰¹å¤„ç†å¤§å°: {batch_size} æ–‡ä»¶/æ‰¹")
    
    # 2. éªŒè¯åˆ—ç»“æ„ä¸€è‡´æ€§
    print(f"\néªŒè¯åˆ—ç»“æ„ä¸€è‡´æ€§...")
    is_consistent, columns, error_msg = validate_column_consistency(xlsx_files)
    
    if not is_consistent:
        print(f"âœ— åˆ—ç»“æ„éªŒè¯å¤±è´¥: {error_msg}")
        return False
    
    print(f"âœ“ åˆ—ç»“æ„ä¸€è‡´ï¼Œå…± {len(columns)} åˆ—")
    
    # 3. æ‰¹é‡è¯»å–å’Œå¤„ç†æ•°æ®
    print(f"\nå¼€å§‹æ‰¹é‡å¤„ç†æ•°æ®...")
    start_time = time.time()
    
    try:
        # ä½¿ç”¨è¿›åº¦æ¡
        with tqdm(total=len(xlsx_files), desc="è¯»å–æ–‡ä»¶", unit="file") as pbar:
            batch_dataframes, total_rows = batch_process_files(
                xlsx_files, 
                batch_size=batch_size,
                max_workers=max_workers,
                progress_bar=pbar
            )
        
        # æ˜¾ç¤ºå†…å­˜ä½¿ç”¨æƒ…å†µ
        mem_info = memory_monitor.get_memory_info()
        print(f"\nå†…å­˜ä½¿ç”¨: {mem_info['current_mb']:.1f}MB (å·²ç”¨: {mem_info['used_mb']:.1f}MB, {mem_info['percent']:.1f}%)")
        
        # 4. æœ€ç»ˆåˆå¹¶æ‰€æœ‰æ‰¹æ¬¡
        print(f"\nåˆå¹¶æ‰€æœ‰æ‰¹æ¬¡æ•°æ®...")
        if len(batch_dataframes) > 1:
            final_df = pl.concat(batch_dataframes, rechunk=True)
        else:
            final_df = batch_dataframes[0]
        
        # é‡Šæ”¾ä¸­é—´ç»“æœ
        del batch_dataframes
        gc.collect()
        
        read_time = time.time() - start_time
        print(f"âœ“ æ•°æ®åˆå¹¶å®Œæˆ (å·²æŒ‰æ–‡ä»¶æ—¥æœŸé¡ºåºæ’åˆ—)")
        print(f"æœ€ç»ˆå½¢çŠ¶: {final_df.shape}")
        print(f"å¤„ç†æ—¶é—´: {read_time:.2f}ç§’")
        
    except Exception as e:
        print(f"âœ— æ•°æ®å¤„ç†å¤±è´¥: {e}")
        return False
    
    # 5. ä¿å­˜ç»“æœ
    if output_file is None:
        output_file = Path(input_dir) / "merged_all_polars_sorted.xlsx"
    else:
        output_file = Path(output_file)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_file.parent.mkdir(parents=True, exist_ok=True)
    
    print(f"\nä¿å­˜åˆå¹¶ç»“æœåˆ°: {output_file}")
    save_start = time.time()
    
    try:
        # è½¬æ¢å›pandaså¹¶ä¿å­˜
        # æ³¨æ„ï¼šå¯¹äºè¶…å¤§æ–‡ä»¶ï¼Œè¿™ä¸€æ­¥å¯èƒ½æ˜¯ç“¶é¢ˆ
        df_pandas = final_df.to_pandas()
        df_pandas.to_excel(output_file, index=False, engine='openpyxl')
        
        # é‡Šæ”¾å†…å­˜
        del df_pandas
        del final_df
        gc.collect()
        
        save_time = time.time() - save_start
        
        print(f"âœ“ æ–‡ä»¶ä¿å­˜æˆåŠŸ")
        print(f"ä¿å­˜æ—¶é—´: {save_time:.2f}ç§’")
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_time = time.time() - start_time
        print(f"\n=== åˆå¹¶ç»Ÿè®¡ ===")
        print(f"è¾“å…¥æ–‡ä»¶æ•°: {len(xlsx_files)}")
        print(f"æ€»è¡Œæ•°: {total_rows}")
        print(f"æ€»åˆ—æ•°: {len(columns)}")
        print(f"è¾“å‡ºæ–‡ä»¶: {output_file.name}")
        print(f"æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"å¹³å‡å¤„ç†é€Ÿåº¦: {len(xlsx_files)/total_time:.1f} æ–‡ä»¶/ç§’")
        print(f"ğŸ¯ æ•°æ®å·²æŒ‰æ–‡ä»¶åæ—¥æœŸé¡ºåºæ­£ç¡®æ’åˆ—")
        
        # æœ€ç»ˆå†…å­˜ä½¿ç”¨æƒ…å†µ
        final_mem = memory_monitor.get_memory_info()
        print(f"æœ€ç»ˆå†…å­˜ä½¿ç”¨: {final_mem['current_mb']:.1f}MB (å¢åŠ : {final_mem['used_mb']:.1f}MB)")
        
        return True
        
    except Exception as e:
        print(f"âœ— æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°ï¼Œæ”¯æŒå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨Polarsä¼˜åŒ–çš„Excelæ–‡ä»¶åˆå¹¶å·¥å…· - æ™ºèƒ½æ—¥æœŸæ’åºç‰ˆæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
æ™ºèƒ½æ—¥æœŸæ’åºæ”¯æŒ:
  æ”¯æŒæ–‡ä»¶åæ ¼å¼: YYYY_MMDD_* å’Œ MMDD_*
  æ’åºç¤ºä¾‹: 2023_0101_* < 2023_0328_* < 2023_1102_* < 2024_0101_*
           0101_* < 0328_* < 1102_* (é»˜è®¤ä½¿ç”¨2024å¹´)

ä½¿ç”¨ç¤ºä¾‹:
  python %(prog)s merged/                               # åˆå¹¶mergedç›®å½•ä¸‹æ‰€æœ‰xlsxæ–‡ä»¶
  python %(prog)s merged/ -o final_merged.xlsx         # æŒ‡å®šè¾“å‡ºæ–‡ä»¶å
  python %(prog)s merged/ --batch-size 100             # è®¾ç½®æ‰¹å¤„ç†å¤§å°
  python %(prog)s merged/ --max-workers 8              # è®¾ç½®æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
  python %(prog)s merged/ --memory-limit 90            # è®¾ç½®å†…å­˜ä½¿ç”¨é™åˆ¶
        """
    )
    
    parser.add_argument('input_dir', help='åŒ…å«xlsxæ–‡ä»¶çš„è¾“å…¥ç›®å½•')
    parser.add_argument('-o', '--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ï¼šè¾“å…¥ç›®å½•/merged_all_polars_sorted.xlsxï¼‰')
    parser.add_argument('--batch-size', type=int, default=50,
                       help='æ‰¹å¤„ç†å¤§å°ï¼Œå³æ¯æ‰¹å¤„ç†çš„æ–‡ä»¶æ•°ï¼ˆé»˜è®¤ï¼š50ï¼‰')
    parser.add_argument('--max-workers', type=int,
                       help='æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°ï¼ˆé»˜è®¤ï¼šCPUæ ¸å¿ƒæ•°*0.8ï¼‰')
    parser.add_argument('--memory-limit', type=int, default=80,
                       help='å†…å­˜ä½¿ç”¨é™åˆ¶ç™¾åˆ†æ¯”ï¼ˆé»˜è®¤ï¼š80ï¼‰')
    
    args = parser.parse_args()
    
    success = merge_with_polars(
        input_dir=args.input_dir,
        output_file=args.output,
        batch_size=args.batch_size,
        max_workers=args.max_workers,
        memory_limit=args.memory_limit
    )
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()